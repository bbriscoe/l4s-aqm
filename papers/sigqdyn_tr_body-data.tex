% !TeX root = sigqdyn_tr.tex
% ================================================================
\section{Solution: Expected Service Time}\label{sec:exp_svc_time}

As already explained, to minimize control path delay and consequently to minimize the blame shifting problem for an immediate AQM, the metric to measure the queue needs to base packet marking on the delay that each packet causes to other packets, not on the delay other packets cause to it. So we need to measure the queue backed up behind the packet about to be marked, not in front of it. But we still need to measure the queue in time units, not bytes or packets, so that any AQM algorithm is robust to varying link rate.

Two approaches will be proposed . Both start with the backlog measured instantaneously at dequeue, then translate it into the expected time needed to drain this backlog---thus both measure the `expected service time':
\begin{itemize}[nosep]
	\item Time-based backlog;
	\item Scaled sojourn time.
\end{itemize}

EST is not a new idea --- many AQMs measure queue delay in a similar way. The difference is that previously the way to measure delay was just thought to be a question of expediency. Whereas we now better understand the principles that determine what to do, and what not to do.

\subsection{Time-Based Backlog}\label{sec:time-based_backlog}

In this approach, as each packet is about to be dequeued from the head of the queue, the expected service time to clear the backlog behind it is calculated as
\[\mathbb{E}(\mathrm{svc\_time}) = \mathrm{(backlog\_deq)}\times \frac{\mathrm{avg\_serializn\_time}}{\mathrm{(avg\_pkt\_size)}},\]
or in English, the expected service time, \(t_b^*\), to clear the backlog is the backlog at dequeue, \(b\) (e.g.\ in bytes), multiplied by the recent average serialization time of each packet, \(t_s^*\) and divided by the recent average packet size (in bytes), \(s^*\).

Multiplying by the quotient on the right is the same as dividing by the average drain rate. As with averaging any rate, the quotient should be calculated as a quotient of averages, not an average of quotients. This is particularly important if the drain rate varies considerably. Also the averages should be exponentially weighted moving averages (EWMAs) with high gain, e.g. \(g=\sfrac{1}{2}\), so that they respond rapidly to changing delivery rate. The gain should be an integer power of 2 so that it can be implemented as a bit-shift.

For instance, assuming the times when dequeue of the previous packet started and ended were stored as \(t_1\) \& \(t_2\) and the packet size was \(s\), the EWMAs would be updated as
\begin{align}
	t_s^* &\pluseq g\left((t_2-t_1) - t_s^*\right)\notag\\
	s^*   &\pluseq g(s - s^*)\notag
\intertext{The expected time to clear the backlog is then,}
	t_b^* &= b * t_s^* / s^*.\label{eqn:t-based_backlog}
\end{align}
While the buffer is non-empty, the time that dequeue ends, \(t_2\) will typically become the time that serialization of the next packet starts. Reusing the same time value for both will ensure that any error introduced by coarse clock precision is averaged out. 

On the other hand, if the buffer was empty when the previous packet finished dequeuing, the time that serialization took has to be used, without including the idle time waiting for the next dequeue to start.

Note that any media acquisition delay should not be counted, and the backlog that builds while waiting to acquire the medium should not be counted for AQM marking, because it is not caused by the load from the sender, and therefore cannot be reduced by getting the sender to slow down.

\subsubsection{Rationale for Time-Based Backlog}\label{sec:time-based_backlog_justify}

The time-based backlog approach assumes that the drain rate to clear the backlog will be similar to that averaged over the last few packets. There is no good reason to believe that the recent drain rate is a good estimator of the drain rate in the near future.\footnote{For instance, a radio link is continually testing different rates to find which is the best and if a queue is continually yielding to a higher priority queue, it will proceed in fits and starts.} However, for the purpose of signalling congestion, the recent drain rate gives the best available estimate of the time to drain the backlog, which itself was a result of the recent drain rate.

It should be pointed out that sojourn time also measures the drain rate over the last few packets. But we have already shown that it ignores the current backlog \emph{behind} the head packet.

One might consider estimating the recent drain rate from the size of just the single most recent head packet and the time to dequeue it. However, such an approach is prone to errors due to coarse clock precision or interruptions affecting access to the clock. By using EWMAs, any such errors should average out, while using a high gain (about \(\sfrac{1}{2}\)) keeps the measurement lag down to about two packets.\footnote{The approach in PIE is similar, except it averages the drain rate over sixteen contiguous packets, and whenever the queue is not that long, the last available average rate is used.}

\subsubsection{Size-Adjusted Threshold(s)}\label{sec:time-adj_thresh}

The following technique is an optimization of the time-based backlog. It avoids the per-packet division in \autoref{eqn:t-based_backlog} above.

It is easiest to explain with an example AQM algorithm. Say, for instance that the AQM marks packets if queuing delay exceeds a simple step threshold, \(T\). Then, as each packet is dequeued, instead of comparing the time-based backlog with the threshold queuing delay, the AQM marks a packet if
\begin{equation}
	b * t_s^* \ge s^* * T.
\end{equation}
In other words, instead of using the average packet size to scale down the backlog, it is used to scale up the threshold.

A similar approach would be used for other AQM functions. For instance, if the likelihood of marking increases by a linear ramp function, both the min and max thresholds of the ramp would be scaled up by \(s^*\).

%An alternative optimization would be to ammortize the per packet calculation over a certain number of packets by accumulating the combined dequeue times of a certain number of packets and accumulating the sum of their sizes. Then every so often updating the two EWMAs, and calculating \(s^* * T / t_s^*\) to give a new threshold in bytes to compare the backlog against. However, the per-packet processing cost of the original size-adjustment is already fairly minimal (two adds, a bit-shift and two integer-multiplies).

\subsection{Scaled Sojourn Time}\label{sec:scaled_svc_time}

Another approach would be to scale the sojourn time by the ratio of the backlogs at dequeue and enqueue. That is, the expected service time at any instant would be:
\[\mathbb{E}(\mathrm{svc\_time}) = \mathrm{sojourn\_time} \times \frac{\mathrm{backlog\_deq}}{\mathrm{backlog\_enq}},\]
where \(\mathrm{backlog\_enq}\) can be written into the packet's metadata at enqueue (along with the arrival time, which is already written at enqueue in existing sojourn implementations).

\subsubsection{Rationale for Scaling Sojourn Time}\label{sec:inst_svc_time_justify}

Scaled sojourn time is comparable to the above `time-based backlog' approach, but with the drain rate measured over the sojourn time of each head packet, which is equivalent to \(\mathrm{backlog\_enq}/\mathrm{sojourn\_time}\). There are two disadvantages, and one advantage, to measuring over a sojourn time.
\begin{description}
	\item[Disadvantage 1:] The measurement delay depends on the queuing delay, which makes it problematic to signal bursts quickly;
	\item[Disadvantage 2:] Each sojourn measurement is sensitive to errors reading the clock and, when the ratio of the backlogs is large, as it is during a burst, any error will be greatly magnified;
	\item[Advantage 1:] Like sojourn time, scaled sojourn time can be measured over an arbitrarily complex set of queues, by only measuring the time of first enqueue and last dequeue and the backlog at enqueue and dequeue times.
\end{description}

Scaled sojourn time would not normally be of interest because of the two disadvantages. However, where an existing deployment or a complex queue structure makes the other approaches infeasible, the advantage of scaled sojourn time might outweigh these disadvantages (but see \S\,\ref{sec:sojourn-distrib}).

Scaling the sojourn time might also make more sense if an implementation is already measuring the sojourn time for another reason. Then it will not need any additional measurement code, because it might already need to maintain the backlogs to do basic queue handling.

Geometric and algebraic analysis of scaled sojourn time as well as ideas for efficient implementation of the division are given in \autoref{sec:scaled_sojourn_details}

\subsection{Distributed Queues}\label{sec:sojourn-distrib}

Using sojourn time leverages the advantage that it can be measured across a complex set of queues, including the case where the initial enqueue and the final dequeue routines are distributed across different machines or processors, as already mentioned (separate clocks would need to be synchronized).

This could include the case where the inputs are located on multiple client machines (e.g.\ mobile user equipment, WiFi stations, cable modems or passive optical network modems) while the output is a located at an aggregation node (e.g.\ a cellular base station (eNodeB)~\cite{Tan09:AQM_uplink_patent}, a WiFi access point (AP), a centralized controller for multiple WiFi APs, a cable modem terminal server (CMTS) or optical line termination (OLT) equipment), with a multiplexed access network between the clients and the aggregation node.

In complex cases like these, if minimization of measurement delay is important, the best approach to use will depend on which of metrics are most feasible to measure and communicate to the dequeue process, which will depend on the architecture of the distributed queues. \autoref{tab:distrib-qs} tabulates which metrics are needed by which approach.

\begin{table*}[h]
	\begin{center}
		\begin{tabular}{ll|cc}
						& 				& Time-based backlog & Scaled sojourn time\\
			\hline
			\multirow{2}{*}%
			{enqueue time}& arrival time		& -					& \checkmark \\
						& backlog				& -					& \checkmark \\
			\hline
			\multirow{4}{*}%
			{dequeue time}& departure time		& \checkmark		& \checkmark \\
						& backlog				& \checkmark		& \checkmark \\
						& serialization time	& \checkmark		& - \\
						& packet size			& \checkmark		& - \\
		\end{tabular}
	\end{center}
	\caption{Metrics needed by each approach}%
	\label{tab:distrib-qs}
\end{table*}

Note that the backlog at enqueue time and the backlog at dequeue time need to include all the data buffered between the two, not just that in the ingress and egress buffers. Therefore the backlog metric is probably the critical factor for feasibility. And given both approaches need the backlog at dequeue time, and scaled sojourn also needs the backlog at enqueue time, scaled sojourn might end up being the more complex approach.`

For instance, on a single machine, the \texttt{count\_enq} variable would be available in a memory shared between ingress and egress. But if the ingress and egress are separate, the ingress machine would have to communicate the \texttt{count\_enq} variable to the egress over a (preferably non-blocking) control channel, so that the egress could calculate \texttt{backlog\_deq} by subtracting \texttt{count\_deq}. 

Certain access network technologies, e.g.\ those for cellular radio access networks, already include such a control channel, over which buffer status report (BSR) control messages are sent from the user equipment at the ingress to the radio network controller. The delay to access a control variable at the input machine from the output machine would be larger than that in a non-distributed system, but it would at least be a known, constant delay. So the control system could still provide robust metrics to control queuing in the data channel.

As well as the aggregation node using expected service time (EST) to apply congestion signalling within the final dequeue routine (effectively on behalf of the input queue), the aggregation node could also use EST to govern the scheduling algorithm for controlling each client's inward (upstream) access rate into the shared medium, by altering the rate at which it granted medium access slots to each client.

\subsection{Applicability of Expected Service Time}\label{sec:inst_svc_time_applic}

Using any of the approaches in \S\,\ref{sec:exp_svc_time} to calculate EST would improve timeliness relative to using sojourn time or other techniques to measure queue delay. However, it would not be worth modifying an existing deployment unless all other delays were going to be removed at the same time. 

It might be thought that an algorithm like the proportional integral (PI) controller\footnote{Used in QCN~\cite{IEEE802.1Qau:Ethernet_QCN}, PIE~\cite{Pan17:PIE}, PI2~\cite{DeSchepper16a:PI2} or the base AQM of DualPI2~\cite{Briscoe15e:DualQ-Coupled-AQM_ID}.} already takes account of the change in queuing delay between samples, so changing the queuing delay measurement itself seems redundant. However, using EST actually ensures that a PI algorithm takes account of the change between the latest queue delay measurements at each sample time, not between two outdated measurements.

It might also be thought that PI controllers do not need to care so much about instantaneous measurements, because they are maintaining the fairly large queue that is needed by classic TCP algorithms like Reno, Cubic, Compound or BBR. However, even though a PI algorithm only samples the queue fairly infrequently (relative to packet serialization time), using an out of date queue metric makes it necessary to introduce extra heuristic code to deal with the resulting sloppiness.

For instance, in the case of PIE~\cite{Pan17:PIE}, some heuristic code suppresses any drop once the last sample of queue delay falls below half the target delay.\footnote{As long as some other conditions hold that are not important here.} This is an attempt to suppress drop when the queue is draining after the load has gone idle. However, it is ineffective if sojourn time is used to measure the queue, because the sojourn time does not reduce until after the last packet (as explained on the right of \autoref{sojourn-prob}). Using EST whenever it is sampled should eliminate the need for this heuristic because it takes account of the reducing backlog as the queue drains.\footnote{Indeed, this was the original motivation for this work.}

EST is also applicable to the CoDel algorithm for the same reasons---sojourn time fails to take account of the evolution of the queue after the head packet was enqueued (again, as in \autoref{sojourn-prob}). This can tend to cause the AQM to continue dropping or marking packets at the end of a flow, because the sojourn time does not recognize that the queue has gone below the target delay. The CoDel code in Linux includes a heuristic to exit dropping mode when the backlog goes below 1\,MTU, but that still continues dropping mode until the last packets of a flow, and tail loss is particularly problematic for a flow to detect.

EST is particularly applicable to a simple AQM algorithm like the time-based shallow threshold recommended for DCTCP in~\cite{Bai16:MQ-ECN} or the native AQM for L4S traffic in DualPI2~\cite[Appx.\ A]{Briscoe15e:DualQ-Coupled-AQM_ID} or Low Latency DOCSIS~\cite{CableLabs:DOCSIS3.1}. It would be applicable whether the threshold is a simple step, or a probabilistic ramp like the RED function (but based on instantaneous queue delay, not smoothed queue length), or a deterministic ramp or convex function of instantaneous queueing delay, as in Curvy RED~\cite[Appx.\ B]{Briscoe15e:DualQ-Coupled-AQM_ID}. The queue in these cases is intended to be very shallow, so it might seem that the extra measurement delay would be minimal. However, the sensitivity of these very low delay schemes to burstiness makes it particularly important to ensure that bursts are measured rapidly and correctly.

EST could apply to many types of queue, not just packet queues, as long as the size of each job is quantified in common units that are additive. Examples include, but are not limited to, queues of datagrams, frames or packets, as well as message queues, call-server queues, computer process scheduling queues, storage queues (e.g. SSD or disk), workflow queues for mechanical or human-operated stages of tasks. 

As well as dropping or ECN-marking, different sanctions could be applied using the same basic ideas. Examples include, but are not limited to: truncating or otherwise damaging the data or checksum of a message or packet but preserving the information necessary for delivery; rerouting; delaying; downgrading the class of service; and tagging.

% ================================================================
\section{Marking Fairness}\label{sec:marking_fairness_discuss}

\subsection{Marking Fairness Experiments}\label{sec:marking_fairness_expts}

\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{experimental-AQM-root_rtt_v_util-q-ratio-prague-EST-v-SOJ-bursts1ms250us0}
	\includegraphics[width=\linewidth]{experimental-AQM-root_rate_v_util-q-ratio-prague-EST-v-SOJ-bursts1ms250us0}
	\caption{TBA}
\end{figure*}

\subsubsection{EST-based Marking Fairness}\label{sec:marking_fairness_expts_est}

\begin{figure*}[t!]
	\centering
	\includegraphics[width=\linewidth]{est-fairnessSumBeta10625}
	\includegraphics[width=\linewidth]{est-fairnessSumBeta125}
	\includegraphics[width=\linewidth]{est-fairnessSumBeta225}
	\caption{EST-based marking fairness of two flows wrt capacity share, \(\lambda\), and relative burstiness, \(\beta\).\\
	\(\lambda_a+\lambda_b=100\%; \quad\mathrm{top:} \beta_a+\beta_b=1.0625; \quad\mathrm{middle:} \beta_a+\beta_b=1.25 
	\quad\mathrm{bottom:} \beta_a+\beta_b=2.25\). 
	The left-hand charts are the same as the right, except they exclude two scenarios that otherwise obscure the other plots}\label{fig:est-fairness-range}
\end{figure*}

\autoref{fig:est-fairness-range} shows the degree to which EST-based ECN marking is or is not focused onto the more bursty of a pair of flows indexed as \(a\) \& \(b\). Both flows were modelled as unresponsive in a time-slotted model similar to the example in \autoref{fig:marking-fairness5050}b). So the results are not necessarily an accurate reflection of a real AQM, but they should at least be indicative of the likely outcome.

The charts show the ECN marking level that results from scanning the scenario parameters across two dimensions:
\begin{enumerate}
	\item The capacity share of flow \(a\), \(\lambda_a\) is varied from \sfrac{1}{32} to \sfrac{1}{2} and the share the other flow \(b\) is also varied so that it fills the remainder of the link (\(\lambda_a+\lambda_b=100\%\))). The left-hand chart of each pair is identical to the right-hand chart except, to help pick out the plots, the last two capacity-share scenarios are omitted.
	\item The normalized burst size of flow \(a\), \(\beta_a\) is increased from \sfrac{1}{16} in steps of \sfrac{1}{16}, while the burst size of flow \(b\) is reduced such that the sum of both burst sizes is constant. The sum is 1.25 in the top plots, and 1.0625 in the bottom. 	Normalization is relative to the ECN marking threshold, so a sum of 1.25 means that if bursts from both flows coincide, a previously empty queue would exceed the marking threshold by 25\%.
\end{enumerate}

It can be seen from the right-hand side of any of the plots that, if flow \(a\) utilizes a small fraction of the capacity (up to roughly \sfrac{1}{8}) and if it is even slightly more bursty than the flow \(b\) (which is using more of the capacity), EST-based marking focuses a high fraction of the marking onto the more bursty flow. 

It is also noticeable that wobbles increasingly appear; some so great that at certain points, even when sharing capacity 50:50, the more bursty flow attracts \emph{less} of the marking. It is possible that these wobbles are an artefact of the time-slotting in the model, so a more precise simulation will be necessary.

Working down from top to bottom of \autoref{fig:est-fairness-range}, it can also be seen that, as the combined level of burstiness increases, it pushes the marking level of the more bursty flow up to 100\% over a wider range of capacity shares, ultimately remaining at 100\% across any share of burstiness.

However, it must be admitted that the region where the plots of flow \(a\) and \(b\) cross (for any capacity share, \(\lambda_a\)) is always to the left of centre. The capacity share of \(a\) is never more than half, so this means that there is a range to the left of centre where \(a\)'s marking probability is higher even though both its burstiness and capacity share are lower than \(b\)'s, although this inversion corrects itself as \(b\)'s relative burstiness increases.

\begin{figure*}[t!]
	\centering
	\includegraphics[width=\linewidth]{est-cong-rateSumBeta125}
	\caption{EST-based congestion-rate of two flows wrt capacity share, \(\lambda\), and relative burstiness, \(\beta\).\\
		\(\lambda_a+\lambda_b=100\%; \quad\mathrm{top:} \beta_a+\beta_b=1.0625; \quad\mathrm{middle:} \beta_a+\beta_b=1.25 
		\quad\mathrm{bottom:} \beta_a+\beta_b=2.25\) (same as \autoref{fig:est-fairness-range}). 
		The left-hand charts are the same as the right, except they exclude two scenarios that otherwise obscure the other plots}\label{fig:cong-rate-range}
\end{figure*}

Focusing again on the right hand side of the charts (where flow \(a\) is more bursty than \(b\)), it may seem counter-intuitive that those flows with a smaller share of the capacity attract a higher marking probability. Even though \(a\)'s marking probability is still generally higher than \(b\)'s, the difference continually narrows, even where \(a\) is considerably more bursty than \(b\).

The explanation is that, when the size of flow \(a\)'s bursts relative to \(b\)'s remains the same (on the same vertical), but its share of capacity increases, its bursts will become more closely spaced. Then, they are more likely to arrive behind some of \(b\)'s traffic. So flow \(a\)'s marking probability will decrease as its capacity share increases.

Also it should be kept in mind that two flows with the same burstiness (on the vertical line down the middle of the plots) would be expected to have the same marking \emph{probability} even if they have different shares of capacity. But a flow with a lesser share of the capacity will attract a proportionately lesser share of the \emph{volume} of marks. This is explained in \autoref{fig:cong-rate-range}, which shows the same traffic scenario as the middle of \autoref{fig:est-fairness-range}, but the metric on the y-axis is normalized congestion-rate, which represents the proportion of link throughput that is marked, rather than just the proportion of flow \(a\). Or formally, the normalized congestion rate of flow \(a\), \(\nu_a = \lambda_a p_a\). With this metric it can be seen that, for the same relative burstiness (same vertical), the proportion of marks increases with capacity share, as would be expected intuitively.

\begin{figure*}
	\centering
	\includegraphics[width=\linewidth]{soj-fairnessSumBeta10625}
	\includegraphics[width=\linewidth]{soj-fairnessSumBeta125}
	\includegraphics[width=\linewidth]{soj-cong-rateSumBeta125}
	\includegraphics[width=\linewidth]{soj-fairnessSumBeta225}
	\caption{Sojourn-based marking fairness of two flows wrt capacity share, \(\lambda\), and relative burstiness, \(\beta\).\\
		\(\lambda_a+\lambda_b=100\%; \quad\mathrm{top:} \beta_a+\beta_b=1.0625;\) upper (marking prob) and lower (congestion-rate) middle: \(\beta_a+\beta_b=1.25 
		\quad\mathrm{bottom:} \beta_a+\beta_b=2.25\) (same as \autoref{fig:est-fairness-range}). 
}\label{fig:soj-fairness-range}
\end{figure*}

\subsubsection{Sojourn-based Marking Fairness}\label{sec:marking_fairness_expts_soj}

For comparison, \autoref{fig:soj-fairness-range} shows the ECN marking that results from sojourn-based marking under the same traffic scenarios as the EST-based marking in \autoref{fig:est-fairness-range} (note that the lower middle row is the same scenario as the upper middle, but the metric is normalized congestion-rate, which can be compared with \autoref{fig:cong-rate-range}).

The most obvious failing can be seen on the left-hand half of the lowest row (\(\beta_a+\beta_b=2.25\)), but also on the far-left of the other rows, where flow \(a\)'s marking exceeds \(b\)'s even though its burstiness and capacity share are both lower.
Similarly, on the right of the plots, no matter how bursty \(a\) becomes, its marking probability never exceeds \(b\)'s. Thus, sojourn-based marking sometimes perversely rewards burstiness and penalizes smoothness.

The second most obvious failing is the much lower overall marking probability in any of the scenarios, given the high degree of burstiness in all scenarios. Even when the bursts of flow \(a\) alone all exceed twice the marking threshold (\(\beta_a>2\) in the bottom row), marking is no higher than 60\% (in contrast, as  \(a\)'s bursts become smaller its marking perversely rises to 100\%). And in the middle case (\(\beta_a+\beta_b=2.25\)), even when all \(a\)'s bursts exceed the threshold (\(\beta_a>1\) the marking probability only lies in the 10\%--20\% range.

\subsection{What Marking would be Fair?}\label{sec:marking_fairness_definition}

As remarked in \S\,\ref{sec:fairer_marking} it is obvious when marking is extremely unfair. For instance, if a bursty flow is using fraction \(\lambda\) of the capacity on average, but attracting less than fraction \(\lambda\) of the marking. However, it is not obvious how much more marking it would be fair to apply to a flow for bursts of a particular size relative to those of another flow.

The doctoral research of Wischik~\cite{Wischik99:Mark_Fairly, Wischik99:Large_Dev_PhD} and sample path shadow pricing~\cite{Kelly98:Shadow_prices_prop_fair} on which it is based appear to be the only work to tackle the question of how to define fair marking for anything but smooth flows. Wischik considers a number of possible definitions of fair marking, which is reduced down to the following three candidates, all of which are intended for offline analysis only, and infeasible for a live marking algorithm. Also all are defined in relation to packet loss, and all assume high statistical multiplexing of flows at a resource:
\begin{description}
	\item[Effective bandwidth:] EB was developed in the context of flow admission control. The EB of a variable rate flow is somewhere between its mean and peak throughputs. A bursty flow can be replaced by another flow with the same effective bandwidth without altering the resulting loss probability, including replacement by a flow with constant throughput equal to the effective bandwidth. So it would be fair to mark flows in proportion to their effective bandwidths.
	\item[\boldmath\(\Delta{L}\):] The function \(L(Y)\) is defined as the volume of loss at a resource when presented with load \(Y\). Then \(\Delta{L(Y)}\) is the change in the loss volume when the flow under consideration is removed, which is the standard definition of a shadow price, so should provide the basis for fair marking. 
	\item[Sample Path Shadow Pricing:] SPSP (\autoref{fig:spsp}) marks every packet that, if removed, would have resulted in one less packet being dropped.
\end{description}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\columnwidth]{spsp}
	\caption{Schematic of Sample Path Shadow Pricing (SPSP) with one timeslot per equisized packet for illustration. A packet is marked (in red) if removing it would have resulted in one less packet being dropped}\label{fig:spsp}
\end{figure}

Wischik explains that each definition has aspects in common with the others, but they differ in their goals, assumptions and user models. 

\(\Delta{L}\) suffers from not being `incrementally fair'. As flows are added to the load, even if they are equally bursty and of equal average throughput, the rise in the volume of loss is greater for each additional flow added. So, with a certain load, imagine that the \(\Delta{L}\) due to removing any one flow is 0.3\%, but removing two equal flows reduces loss by only 0.5\%. Then if two flows band together, and internally share the marks they get under the \(\Delta{L}\) scheme between themselves, they would get only 0.25\% marking each, thereby proving that \(\Delta{L}\) is not incrementally fair.

In contrast, SPSP is incrementally fair because it acts at the granularity of packets, and is agnostic to whether packets band together under flows or users. This also means that SPSP is concerned with precisely which packets to mark, whereas \(\Delta{L}\) only knows what proportion of marks to allocate to each flow.

Like \(\Delta{L}\), EB can only say what proportion of marks should be applied to each flow but EB only knows the relative proportions; it does not know how many marks to apply overall, although this can be remedied if an exchange rate between drops and marks is defined. 

Thus, in the words of Wischik, ``SPSP is best''. However, like all the schemes, SPSP can only be applied offline---in retrospect. In the case of SPSP, this is because it is meant to mark the packets that were in the queue as it built up to the point of overflow, but many of those packets will already have left the queue by the time the queue does overflow (for instance the first four marked packets in \autoref{fig:spsp}).

Nonetheless, SPSP represents an ideal scheme that a practical marking algorithm
ought to aspire to. %Wischik proposes a marking algorithm that does just that.
% It is called Reach Overload, Send ECN (ROSE) and works as follows. Whenever
% the queue size exceeds a threshold, mark all packets in the queue. The
% threshold, \(b\), is adaptively determined as follows: for every packet that
% would have been marked by SPSP, decrease \(b\) by \(\kappa\epsilon\). For
% every packet that is marked, increase \(b\) by \(\epsilon\) \(\epsilon\) is a
% small fixed quantity and \(\kappa\) represents the number of marks that are
% equivalent to a drop, which Wischik recommends should be somewhat greater than
% one for robustness.
However, the goals of the present work are wider than those in Wischik. We particularly want to maintain very low queuing delay, but we do also want to ensure marking is as fair as possible. Therefore, it will be worth taking note of the two questions that Wischik poses to assess the fairness of a marking algorithm:
\begin{enumerate}[nosep]
	\item Does it marks packets that caused overflow, or does it mark innocent packets that arrived later?
	\item Does it mark in the busy period leading up to the overflow?
\end{enumerate}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\columnwidth]{est-spsp}
	\caption{Marking based on Expected Service Time compared against Sample Path Shadow Pricing}\label{fig:est-spsp}
\end{figure}
For marking based on expected service time (EST), we redefine overflow as exceeding the queuing delay target (in time units not bytes). Then, using the example scenario in \autoref{fig:est-spsp}, we can answer the questions and justify where EST diverges. 

\begin{enumerate}[nosep, label=Q\arabic*.]
	\item EST does not mark any innocent packets; however it does not mark the packets that contributed to excess delay but were dequeued after excess delay had ended (the pink packets to the right of the red ECN-marked packets). 
	\item EST marks as many packets in the busy period leading up to excess delay as possible, but it cannot mark those that had already been served when excess delay was first detected (the pink packets to the left).
\end{enumerate}
From the earlier analysis of EST-based marking of traffic bursts (\S\,\ref{sec:marking_fairness_expts_est}), it can be seen that EST will rarely miss any packets in the build-up to excess delay, because most of the packets of a burst are still queued when the tail arrives.\footnote{Where the difference between the burst rate and the service rate of the queue is less pronounced, this would not be true. However, in the earlier analysis, bursts were always assumed to arrive in one timeslot.} Also stopping EST marking as soon as the excess delay has gone away seems preferable for two reasons:
\begin{itemize}
	\item It seems less likely to hit smoother flows, which tend to back up behind a burst, as explained in \S\,\ref{sec:fairer_marking};
	\item When there has been a period of marking, the load arriving from sources will reduce a round trip later. Thus if marking were to continue until the queue was empty, it would tend to cause under-utilization in the following round trip.
\end{itemize}

\subsection{Queue Protection and Marking Fairness}\label{sec:qprot_marking_fairness}

The goal of queue protection (QProt) is to try to eliminate bursty traffic from a shared low latency queue. The ability of EST-based marking to focus on bursts raises the possibility of a crude form of queue protection without having to identify layer-4 flows (in contrast to per-flow QProt specified for DOCSIS~\cite{Briscoe19b:q-prot_ID}).

Here an example design for aggregate QProt is proposed, for instance as an extension to the DualQ Coupled AQM. When a packet is about to be dequeued from the L queue, if the EST of the backlog behind it exceeds the maximum ECN-marking threshold\footnote{The step threshold, or the top of a ramp function.} by some margin, the head packet would be redirected to the back of the C queue.\footnote{Preferably by rearranging pointers, rather than moving the packet data.} The margin might be set, for instance, at twice the depth of the maximum marking threshold, or it might be slightly randomized to discouraging sources from `flying just under the radar'. Once redirection had started, it would continue until the EST at least reduced below the allowed margin, or preferably it could continue until the EST had been brought down to the maximum ECN marking threshold. 

Then, any large bursts would be more likely to be ejected from the L queue, while traffic keeping within the maximum ECN threshold would be more likely to remain in the L queue, without having to sit behind large bursts. Of course there is no guarantee that smooth traffic would not sometimes be redirected, when it happened to arrive in front of a burst. But smooth, well-behaved traffic should never build up behind a burst that had been large enough to be ejected from the L queue.

This technique would cause reordering of any flow it redirected, However, any application receiving data in bursts should not be particularly sensitive to reordering within the bursts, given one assumes it would have to buffer the bursts as they arrive anyway. Nonetheless, any even slight harm due to reordering would help to disincentivize an application from sending in bursts.

If all the traffic was bursty, perhaps because it had passed through a bursty link upstream, aggregated QProt would redirect some traffic from all flows into the C queue, which would just add reordering to all traffic. Per-flow QProt is designed to redirect the most bursty flows until queue delay reduces, so it would not necessarily fare much better in a scenario where burstiness was added to all traffic in the aggregate. However, QProt attempts to focus redirection on only a few flows, even if they are only slightly worse than others, which might help in this case. In practice, most flows would be responsive to congestion signalling so, as long as the marking was fair, aggregate burstiness should result in general under-utilization, rather than endemic reordering.\footnote{Where the IETF draft on L4S~\cite{Briscoe15f:ecn-l4s-id_ID} discusses burstiness from upstream links, it suggests that the pragmatic solution is to improve the configuration of the system as a whole, for instance reducing the burstiness of an upstream link, or increasing the L4S marking threshold at the bottleneck.}

The above aggregate QProt technique is not necessarily only applicable to a DualQ. It is simple enough that it could potentially also be included in a per-flow queue, to protect against the possibility of a bursty flow encapsulated within a VPN alongside smooth flows. For instance, the L4S architecture allows for the possibility that VPNs are separated into two sister per-flow queues for L4S and non-L4S packets. Then the L4S per-`flow' queue could redirect bursts into its non-L4S sister. However, a bursty flow within a VPN is perhaps a corner case that would not warrant such an addition.

% ================================================================
\section{Other Signalling Delays}\label{sec:other_delays}

The introduction enumerated six causes of delay to congestion signals and highlighted two that this memo would focus on. The other four sources of signalling delay are briefly surveyed below, with pointers to where they have been considered in other work.

\subsection{Propagation Delay} Numerous proposals have been made to speed up signalling by sending the signal from the queue back against the flow of traffic, direct to the sender. This can be done in a pure L2 network, e.g. backwards congestion notification (BCN) in IEEE 802.1Qau~\cite{IEEE802.1Qau:Ethernet_QCN} a.k.a.\ Quantized Congestion Notification (QCN), which is now rolled into 802.1Q-2011 and 802.1Q-2014. However, in general signalling backwards is problematic in IP networks, amongst other reasons because the sender has to accept out-of-band packets from any arbitrary source in the middle of the network, which makes it vulnerable to DoS attacks~\cite{IETF_RFC6633:ICMP_SQ_Depr}. 

Therefore, here we will assume that signals are piggy-backed on the forward traffic flow then fed back to the sender via the receiver. However, this does not preclude a solution to the problems of backwards congestion notification.

\subsection{Smoothing Delay} AQMs designed for the Internet's classic congestion controls (TCP Reno, Cubic, Compound, etc.) filter out fluctuations in the queue by smoothing it before using the smoothed measurement as a measure of load to drive the congestion signal. DCTCP~\cite{Alizadeh10:DCTCP} proposed to smooth the signal at the sender, so that the network could send out the signal immediately, without smoothing, and L4S followed this approach~\cite{Briscoe16a:l4s-arch_ID}. This allows the sender to receive the signal without smoothing delay, which is particularly useful in cases where the sender might not need to smooth the signal itself, e.g.\ to detect overshoot when accelerating to start a new flow. Shifting the smoothing function from the network to the sender also makes sense because the network does not know the round trip time (RTT) of each flow, so it has to smooth over the maximum likely RTT. Whereas a sender knows its own RTT and can smooth over this timescale.

\subsection{Signal encoding delay} Previous research has proposed to change the IP wire protocol to provide more bits to signal congestion. Nonetheless, it has been pointed out\footnote{Matt Mathis is believed to have pointed this out first.} that the delay of a unary encoding is inversely proportional to the value being encoded, and the congestion window of a scalable congestion control is also inversely proportional to the value of the congestion signal. So, as flow rates (and consequently congestion windows) increase over the years, at least in general the delay to encode the signal does not increase.\footnote{However, encoding delay does increase with the degree of ACK coalescing.}

Therefore, in this report we have assumed the unary encoding of congestion signals standardized as ECN by the IETF~\cite{IETF_RFC3168:ECN_IP_TCP}. This does not preclude other encodings, e.g. the multi-bit encoding of QCN or minor alterations to the decoding to avoid saturation, such as that in \cite{Briscoe17a:CC_Tensions_TR}.

\subsection{Removing Randomness Delays}\label{sec:rand_delay}

One of the main motivations for the design of Random Early Detection (RED)~\cite{Floyd93:RED} was to break up synchronization between the sawteeth of TCP flows driving the same queue. This still remains an important requirement for all AQM algorithms~\cite{Baker15:AQM_Recommendations}.

AQMs mitigate synchronization by introducing marking or dropping more gradually than a tail-drop buffer would, and to a certain extent by randomizing the marking. 

With clean-slate approaches such as DCTCP in private networks, or incrementally deployable clean-slate approaches like L4S~\cite{Briscoe16a:l4s-arch_ID} for the public Internet, requirements for the network and for end-systems are still in the process of definition. In these clean-slate or slightly dirty-slate cases, it would be possible to require the sender's congestion control to dither its response to congestion signals, so that it would not be necessary to introduce randomness in the network, which adds uncertainty and therefore delay to the congestion signalling channel. 

Any AQM that probabilistically signals congestion with probability \(p\) could deterministically signal congestion by introducing an interval of \(1/p\) packets between each drop or mark. PDPC+~\cite{Sagfors03:PDPC_vary} and CoDel~\cite{Nichols12:CoDel}, which is very similar, use a deterministic rather the probabilistic algorithm to encode the congestion signal. Both AQMs in DualPI2~\cite[Appx.\ A]{Briscoe15e:DualQ-Coupled-AQM_ID} also uses a deterministic algorithm.

The determinism would be lost wherever the AQM was controlling flows multiplexed within one queue without per-flow state, because assignment of each deterministic congestion signal to each flow would become randomized by even slightly random packet arrivals from the different flows~\cite{Briscoe15d:PIE_rvw}.

Nonetheless, whenever a flow is on its own in an AQM, which is a common case for the traffic patterns in many access network designs,  deterministic congestion signalling would reduce signalling delay. This could particularly ease the design of new flow-start algorithms, where the flow introduces microbursts or chirps to sense at what level it starts to congest the link.

Determinism of an AQM is of less importance when the congestion control rather than the AQM determines the spacing between marks. For instance, the duration of the sawteeth of a classical congestion control scales with BDP. So at low BDP, the AQM determines the spacing between marks, but as BDP scales, the congestion control sawteeth move in and out of closed loop control, which determines the duration between `congestion events' with the AQM inactive between times~\cite[\S\,3.3]{Briscoe21c:pi2param}.